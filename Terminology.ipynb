{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Descriptions\n",
    "\n",
    "여기서 말하는 알고리즘의 세가지 주요 특성(key properties)은 다음과 같습니다.\n",
    "\n",
    "1. 파일에 저장될 수 있는 실제 수와 구조의 측면에서 알고리즘에 의해 사용된 표현.\n",
    "\n",
    "2. 트레이닝 데이터가 주어진 경우 알고리즘에서 학습하기 위해 사용된 프로시저.\n",
    "\n",
    "3. 학습된 모델이 주어진 경우 알고리즘에서 예측을 수행하기 위해 사용된 프로시저."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column, Row, Cell\n",
    "\n",
    "- **Column**: single type의 데이터를 나타냄. 한 column의 모든 데이터는 동일한 scale을 가지며 서로 상대적인 의미가 있습니다.\n",
    "\n",
    "\tex) **어떤 대상**의 무게, 높이, 가격 등의 column\n",
    "\n",
    "- **Row**: single entity나 observation을 나타내며 column은 이 entity나 observation에 대해 설명함 많은 row를 가질 수록 문제가 있는 정의역이 늘어납니다.\n",
    "\n",
    "- **Cell**: Row와 Column의 단일 value. category(red)나 실수(1.5) 및 정수(2)가 될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Learning Perspective\n",
    "\n",
    "$$ Output = f(Input) $$\n",
    "\n",
    "가설 함수 $f$ 의 관점에서 데이터를 프레임으로 만듭니다.\n",
    "\n",
    "- Input: Input Variable, Input Vector, Independent Variable\n",
    "\n",
    "- Output: Output Variable, Dependent Variable\n",
    "\n",
    "예측하는 문제에서는 출력이 입력 변수에 종속되어 있기 때문에 독립된 변수로 부터의 관계를 이끌어낼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Science Perspective\n",
    "\n",
    "컴퓨터 과학 용어에서는 프로그램을 통해 입력된 속성들을 출력으로 만듭니다.\n",
    "\n",
    "$$ Output = Program(InputFeatures) $$\n",
    "\n",
    "row를 단일 인스턴스로 간주하여 문제 도메인에 의해 관찰하거나 예측하기도 합니다.\n",
    "\n",
    "$$ Prediction = Program(Instance) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models and Algorithms\n",
    "\n",
    "모델과 알고리즘 사이에서는 많은 혼란이 있지만 여기서는 다음과 같이 정의합니다.\n",
    "\n",
    "$$ Model = Algorithm(Data) $$\n",
    "\n",
    "모델은 데이터로 학습한 특정 표현이며 알고리즘은 학습 과정으로 간주합니다.\n",
    "\n",
    "예를 들어 *decision tree* 또는 *계수 집합(set of coefficients)*은 **모델**이며 *C5.0*, *Least Squares Linear Regression*은 해당하는 모델을 학습하는 **알고리즘**입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning a Function\n",
    "\n",
    "머신 러닝 알고리즘은 입력 변수 $X$ 에서 출력 변수 $Y$ 로 가장 잘 매핑하는 목표 함수 $f$ 를 학습하는 것을 말합니다.\n",
    "\n",
    "$$ Y = f(X) $$\n",
    "\n",
    "예측된 결과 $Y$ 가 정확하다면 더 이상 학습할 필요가 없습니다. 실제로는 입력 변수 $X$와 독립된 에러 $e$\t가 존재합니다.\n",
    "\n",
    "이 오류는 완전히 없앨 수는 없기 때문에 irreducible error라고도 합니다.\n",
    "\n",
    "결국 에러를 최소한으로 줄이기 위한 목표 함수 $f$ 를 찾거나 학습하여 최대한 문제를 근사적으로 해결하는 것에 초점을 맞춥니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric Machine Learning Algorithms\n",
    "\n",
    "가정(Assumption)을 통해 학습을 제한하여 함수를 단순화하는 알고리즘을 *Parametric Machine Learning Algorithm*이라고 합니다.\n",
    "\n",
    "> A learning model that summerizes data with a set of parameters of fixed size(independent of the number of training examples) is called a parametric model. No matter how much data you throw at a parametric model, it won't change its mind about how many parameters it needs.\n",
    "\n",
    "<div style='text-align: right'>-- Artificial Intelligence: A Modern Approach, page 737</div>\n",
    "\n",
    "Parametric algorithm은 두 단계를 거칩니다.\n",
    "\n",
    "1. 함수의 형태를 선택합니다.\n",
    "\n",
    "2. 트레이닝 데이터로부터 함수의 계수(coefficients)를 학습합니다.\n",
    "\n",
    "Linear regression이 이해하기 쉬운 예가 될 수 있습니다.\n",
    "\n",
    "$$ B_0 + B_1 * X_1 + B_2 * X_2 = 0 $$\n",
    "\n",
    "$B_n$은 기울기 및 절편의 계수이며 $X_n$은 입력 변수들입니다.\n",
    "\n",
    "이는 함수로 인한 예측 형태를 이미 Linear하다고 가정하며 이 가정이 잘못되어 잘못된 결과를 초래할 수도 있습니다.\n",
    "\n",
    "몇 가지 다른 예제도 있습니다.\n",
    "\n",
    "- Logistic Regression\n",
    "\n",
    "- Linear Discriminant Analysis\n",
    "\n",
    "- Perceptron\n",
    "\n",
    "Parametric의 이점:\n",
    "\n",
    "- **Simpler**: 이해하기 쉽고 결과를 해석하기 쉽습니다.\n",
    "\n",
    "- **Speed**: 데이터를 매우 빠르게 학습합니다.\n",
    "\n",
    "- **Less data**: 적은 양의 불완전한 데이터로도 충분히 결과를 이끌어낼 수 있습니다.\n",
    "\n",
    "Parametric의 제한점:\n",
    "\n",
    "- **Constrained**: 함수의 형태를 이미 선택했으므로 선택한 형태로 강하게 제한됩니다.\n",
    "\n",
    "- **Limited Complexity**: 복잡한 문제는 해결하지 못하며 간단한 문제에 적합합니다.\n",
    "\n",
    "- **Poor Fit**: 실제로 기본 매핑 함수와 일치하지 않을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonparametric Machine Learning Algorithms\n",
    "\n",
    "매핑하는 함수의 형태에 대해 강력한 전제를 하지 않는 알고리즘을 *Nonparametric Machine Learning Algorithm*이라고 합니다.\n",
    "\n",
    "> Nonparametric methods are good when you have a lot of data and no prior knowledge, and when you don’t want to worry too much about choosing just the right features.\n",
    "\n",
    "<div style='text-align: right'>-- Artificial Intelligence: A Modern Approach, page 757</div>\n",
    "\n",
    "NonParametric Algorithm은 보이지 않는 데이터를 일반화할 수 있으면서도 트레이닝 데이터를 가장 잘 맞추려고 합니다. 목표함수에 대한 가정을 하기 보다는 데이터 사이의 상관관계를 통해 결과를 도출하는 경우가 많습니다. 유명한 알고리즘은 다음과 같습니다.\n",
    "\n",
    "- Decision Trees like CART and C4.5\n",
    "\n",
    "- Naive Bayes\n",
    "\n",
    "- Support Vector Machines\n",
    "\n",
    "- Neural Networks\n",
    "\n",
    "Nonparametric Machine Learning Algorithm의 이점:\n",
    "\n",
    "- **Flexibility**: 많은 함수 형태에 적합합니다.\n",
    "\n",
    "- **Power**: 함수에 대한 가정이 없습니다(또는 약한 가정).\n",
    "\n",
    "- **Performance**: 모델에 대한 예측에 높은 성능을 이끌어 낼 수 있습니다.\n",
    "\n",
    "Nonparametric Machine Learning Algorithm의 제한점:\n",
    "\n",
    "- **More data**: 매핑 함수를 추정하기 위한 많은 트레이닝 데이터가 필요합니다.\n",
    "\n",
    "- **Slower**: 트레이닝을 위해 많은 파라미터가 필요하므로 느립니다.\n",
    "\n",
    "- **Overfitting**: Overfitting으로 인한 실제 부정확한 결과가 도출될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Machine Learning\n",
    "\n",
    "Supervised learning은 학습 과정을 감독하는 교사로 생각할 수 있는 데이터 셋으로부터 학습하기 때문에 붙여진 이름입니다. 우리는 정답을 알고 있어서, 교사를 통해 데이터를 트레이닝 시킬 수 있습니다. 일정 수준 이상의 성능을 나타내면 학습을 중단합니다. Supervised learning problem은 회귀나 분류 문제로 그룹화 될 수 있습니다.\n",
    "\n",
    "- **Classification**: 출력 변수가 카테고리(*red* 또는 *blue*, *disease* 또는 *no disease*)인 경우의 문제\n",
    "\n",
    "- **Regression**: 출력 변수가 실수 값인 경우의 문제(*dollar*, *weight*)\n",
    "\n",
    "- 주로 추천 및 시계열 예측 문제가 일반적입니다.\n",
    "\n",
    "\t- Linear regression 등의 regression 문제\n",
    "\n",
    "\t- Random forest 등의 classification과 regression 문제\n",
    "\n",
    "\t- Support vector machines 등의 classification 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Machine Learning\n",
    "\n",
    "Unsupervised learning은 입력 데이터 $X$ 만 있고 출력 변수가 없는 것입니다.\n",
    "supervised와 다른 이유는 정답과 교사가 없기 때문입니다.\n",
    "알고리즘 자체를 통해 데이터의 상관 관계나 고유한 특징을 파악하여 결과를 도출하는 것이 일반적입니다.\n",
    "Unsupervised learning 문제는 클러스터링이나 연관 문제로 그룹화 될 수 있습니다.\n",
    "\n",
    "- **Clustering**: 구매 행동으로 고객을 분류하는 것과 같이 데이터의 고유한 그룹을 발견하고자 하는 경우\n",
    "\n",
    "- **Association**: A를 구매하는 사람들은 B도 구매하는 경향이 있다는 것처럼 데이터의 규칙을 발견하고자 하는 경우\n",
    "\n",
    "\t- k-means 클러스터링 문제\n",
    "\n",
    "\t- Apriori algorithm을 통한 연관 규칙 학습 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-Supervised Machine Learning\n",
    "\n",
    "일부 데이터에는 라벨이 지정되어 supervised 학습이 가능하지만 대부분이 지정되지 않아 unsupervised 학습과 혼합된 형태입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Error\n",
    "\n",
    "목표 함수를 보다 쉽게 학습할 수 있도록 모델에 의해 단순화 된 가정입니다.\n",
    "일반적으로 parametric 알고리즘이 강한 가정을 가진 함수의 형태이기 떄문에 높은 bias를 요구하고 이를 통해 빠른 학습과 이해가 가능하지만 유연성은 떨어지는 경향이 있습니다.\n",
    "단순화 된 가정을 충족하지 못하는 복잡한 문제에 대해서는 반대로 예측 성능이 낮습니다.\n",
    "\n",
    "- **Low Bias**: 목표 함수의 형태에 대한 비교적 작은 가정\n",
    "\n",
    "\tex) Decision Trees, k-Nearest Neighbors, Support Vector Machines\n",
    "- **High Bias**: 목표 함수의 형태에 대한 비교적 많은 가정\n",
    "\n",
    "\tex) Linear Regression, Linear Discriminant Analysis, Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Error\n",
    "\n",
    "여기서 분산(Variance)의 정의는 서로 다른 트레이닝 데이터를 사용할 때 목표 함수의 추정치가 변경되는 정도입니다.\n",
    "\n",
    "목표 함수는 머신 러닝 알고리즘에 의한 트레이닝 데이터로부터 추정되므로 알고리즘마다 약간의 차이가 있습니다. 이상적으로는 하나의 트레이닝 데이터 셋에서 다음 트레이닝 데이터 셋으로 너무 많이 변경되어서는 안되며 알고리즘은 입력과 출력 변수 사이의 숨겨진 기본 매핑을 선택하는 것이 좋습니다.\n",
    "\n",
    "Variance가 높은 머신 러닝 알고리즘은 트레이닝 셋 데이터의 특성에 크게 영향을 받게 됩니다.\n",
    "이는 트레이닝 데이터의 특성이 매핑 함수를 특성화 하는 데 사용되는 매개 변수의 수와 유형에 영향을 미친다는 것을 의미합니다.\n",
    "\n",
    "- **Low Variance**: 트레이닝 데이터 셋을 변경하면 목표 함수의 추정치에 대한 변경 정도가 작음\n",
    "\n",
    "- **High Variance**: 트레이닝 데이터 셋을 변경하면 목표 함수의 추정치에 대한 변경 정도가 큼\n",
    "\n",
    "### Irreducible Error\n",
    "\n",
    "알고리즘으로는 줄일 수 없는 에러를 말합니다. 입력 변수와 출력 변수의 매핑에 영향을 주지만 알려지지 않은 변수에 의한 요인에 의해 발생될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance Trade-off\n",
    "\n",
    "Supervised machine learning의 목표는 Low bias와 Low variance를 만족하는 것입니다.\n",
    "\n",
    "- Parametric or linear machine learning algorithm은 보통 high bias를 가지지만 low variance를 가집니다.\n",
    "\n",
    "- Nonparametric 또는 nonlinear machine learning 알고리즘은 low bias를 가지지만 high variance를 가집니다.\n",
    "\n",
    "이 두 에러의 균형을 맞추기 위해 다음 Trade-off의 두가지 예가 있습니다.\n",
    "\n",
    "- k-nearest neighbors algorithm은 low bias와 high variance를 가지고 있지만 k 값을 증가 시킴으로써 예측에 기여하는 neighbor의 수를 증가시켜 variance\t를 낮추고 bias가 증가함으로써 균형을 맞출 수 있습니다.\n",
    "\n",
    "- support vector machine algorithm은 low bias와 high variance를 가지고 있지만 C 파라미터를 증가함으로써 variance를 낮추고 bias를 증가시켜 마진에 영향을 줄 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting, Underfitting\n",
    "\n",
    "- **Overfitting**: 트레이닝 데이터에는 좋은 성능을 보이지만 다른 데이터의 일반화에 적절하지 않은 상황을 나타냅니다.\n",
    "\n",
    "- **Underfitting**: 트레이닝 데이터 뿐만 아니라 다른 데이터의 일반화에도 적절하지 않은 상황을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
